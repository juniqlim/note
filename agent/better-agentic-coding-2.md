# 에이전틱 코딩 좀 더 잘하기 2 - LLM의 특성을 알면 더 잘 쓴다

## 왜 LLM의 작동원리를 알아야 하는가
자동차 운전에 엔진 구조를 몰라도 되지만, 레이싱에서는 엔진 특성을 아는 드라이버가 더 빠르다.
에이전틱 코딩도 마찬가지다. LLM이 어떻게 작동하는지 알면, 같은 도구로 더 좋은 결과를 뽑아낼 수 있다.

## LLM은 어떻게 작동하는가

### 토큰화 (Tokenization)
LLM은 글자를 읽지 않는다. 텍스트를 토큰(token)이라는 단위로 쪼개서 처리한다.
"programming"은 하나의 토큰이지만, 흔치 않은 단어는 여러 토큰으로 쪼개진다.
코드에서는 변수명, 함수명, 구문 구조가 각각 토큰이 된다.

이것이 의미하는 것: LLM에게 `calculateTotalPrice`는 `calc_total_price`보다 더 적은 토큰으로 처리될 수 있다. 흔한 네이밍 패턴일수록 LLM이 더 잘 다룬다.

### 다음 토큰 예측 (Next Token Prediction)
LLM의 핵심 메커니즘은 단순하다. 지금까지의 텍스트를 보고, 다음에 올 토큰을 예측한다. 이것을 반복한다.
"코드를 생성한다"는 말은 사실 "다음에 올 코드 토큰을 계속 예측한다"는 뜻이다.

이것은 근본적인 한계를 만든다: LLM은 계획을 세우고 코드를 쓰는 것이 아니라, 한 토큰씩 앞으로 나아간다. 사람이 문장을 쓸 때 전체 구조를 머릿속에 두고 쓰는 것과 다르다.

### 어텐션 (Attention)
"이 토큰은 앞의 어떤 토큰들과 관련이 있는가"를 계산하는 메커니즘이다.
함수 호출을 생성할 때, 앞에서 정의한 함수 시그니처에 어텐션이 걸린다.
이 메커니즘 덕분에 LLM은 멀리 떨어진 맥락을 참조할 수 있다.

하지만 어텐션에도 한계가 있다. 모든 토큰에 균일하게 주의를 기울이지 않는다. 이것이 아래에서 다룰 여러 편향의 원인이 된다.

### 컨텍스트 윈도우 (Context Window)
LLM이 한 번에 볼 수 있는 토큰의 양에는 한계가 있다. 이것이 컨텍스트 윈도우다.
대화가 길어지면 오래된 내용은 잘려나가거나 압축된다.
코드베이스 전체를 한 번에 이해하는 것이 아니라, 창문을 통해 일부를 보는 것에 가깝다.

### 학습 데이터 (Training Data)
LLM은 인터넷의 방대한 텍스트로 학습되었다. GitHub의 코드, Stack Overflow의 답변, 문서들.
이것이 의미하는 것: 학습 데이터에 많이 등장한 언어, 프레임워크, 패턴에서 더 강하다.
Python, Java, JavaScript 같은 메이저 언어는 잘하고, 학습 데이터가 적은 언어일수록 상대적으로 약하다.

## LLM의 특성과 실전 대응

### 1. 최근 편향 (Recency Bias)
**특성**: 긴 대화에서 마지막에 가까운 내용에 더 강하게 영향 받는다.

**대응**:
- 중요한 지시는 대화 끝에 다시 한번 언급한다
- 새 대화를 시작하는 것을 두려워하지 않는다. 맥락이 흐려졌다면 새 대화가 더 낫다
- CLAUDE.md 같은 시스템 프롬프트에 핵심 규칙을 넣으면, 매 턴마다 주입되므로 최근 편향의 영향을 받지 않는다

### 2. 중간 손실 (Lost in the Middle)
**특성**: 긴 입력의 처음과 끝은 잘 기억하지만, 가운데는 놓치기 쉽다.

**대응**:
- 긴 요구사항을 줄 때, 가장 중요한 것을 처음이나 끝에 배치한다
- 한 번에 많은 요구사항을 전달하기보다, 단계별로 나눈다
- 파일을 읽힐 때도 전체보다는 관련 부분만 보여주는 것이 효과적이다

### 3. 동의 편향 (Sycophancy)
**특성**: 사용자의 말에 동의하려는 경향이 있다. "이 코드 괜찮지?" 하면 "네, 좋습니다" 하기 쉽다.

**대응**:
- "이 코드에 문제가 있나?" 대신 "이 코드의 버그를 찾아줘"처럼 구체적으로 요청한다
- 에이전트의 판단에 의존하기보다, 테스트로 검증한다. 1탄의 핵심: 루프를 닫아야 한다
- "맞아?"라고 물으면 "맞다"고 답할 가능성이 높다. 열린 질문을 한다

### 4. 흔한 답으로 수렴 (Mode Collapse)
**특성**: 학습 데이터에서 자주 본 패턴으로 끌려간다. "정석적인" 답을 내놓으려 한다.

**대응**:
- 특정한 제약조건이나 스타일이 있다면 명시적으로 말한다
- 프로젝트의 기존 코드를 참조하게 한다. "이 파일의 스타일을 따라줘"
- CLAUDE.md에 프로젝트 컨벤션을 적어두면, 매번 말하지 않아도 된다

### 5. 상태 추적 부재 (No State Tracking)
**특성**: LLM은 내부적으로 변수를 저장하거나 숫자를 세는 장치가 없다. 괄호 개수, 들여쓰기 깊이를 실수하기 쉽다.

**대응**:
- 복잡한 중첩 구조보다 평탄한(flat) 코드 구조가 LLM에게 유리하다
- 이것은 사람에게도 좋은 코드다. Early return, 작은 함수
- 에이전트가 생성한 코드의 구문 오류는 린터/포맷터로 자동 검증한다

### 6. 한 토큰씩 전진 (Autoregressive)
**특성**: 한번 출력한 토큰은 되돌릴 수 없다. 코드 앞부분을 쓰면서 뒷부분의 구조를 바꿀 수 없다.

**대응**:
- 큰 작업을 작은 단위로 나눈다. 한 번에 1000줄보다 100줄씩 10번이 낫다
- 함수 시그니처(입출력)를 먼저 정의하고, 구현을 요청한다. 앞부분이 확정되어야 뒷부분이 정확해진다
- 1탄에서 말한 "검증 가능한 단위"가 여기서도 통한다

## 정리
LLM의 특성을 알고 나면, 대응법을 정리할 수 있다.
- 작은 단위로 작업하라 → 컨텍스트 윈도우, 중간 손실, 자기회귀 특성 모두에 대한 대응
- 명확하게 말하라 → 동의 편향, 흔한 답 수렴에 대한 대응
- 테스트로 검증하라 → 모든 특성의 한계에 대한 최종 안전망

LLM의 작동원리를 이해하면, 이 조언들이 왜 맞는지 더 깊이 납득할 수 있다.
