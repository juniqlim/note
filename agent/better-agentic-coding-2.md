# 에이전틱 코딩 좀 더 잘하기 2 - LLM의 특성을 알면 더 잘 쓴다

## 왜 LLM의 작동원리를 알아야 하는가
자동차 운전에 엔진 구조를 몰라도 되지만, 레이싱에서는 엔진 특성을 아는 드라이버가 더 빠르다.
에이전틱 코딩도 마찬가지다. LLM이 어떻게 작동하는지 알면, 같은 도구로 더 좋은 결과를 뽑아낼 수 있다.

## LLM은 어떻게 작동하는가

### 토큰화 (Tokenization)
LLM은 글자를 읽지 않는다. 텍스트를 토큰(token)이라는 단위로 쪼개서 처리한다.
흔한 단어는 통째로 하나의 토큰이 되지만, 드문 단어는 여러 토큰으로 쪼개진다. 토큰화 방식은 모델마다 다르다.
코드에서는 변수명, 함수명, 구문 구조가 각각 토큰이 된다.

이것이 의미하는 것: 흔한 네이밍 패턴일수록 적은 토큰으로 처리된다. 토큰 수가 적다고 반드시 성능이 좋아지는 것은 아니지만, 학습 데이터에 자주 등장한 패턴을 LLM이 더 잘 예측하는 경향이 있다.

### 다음 토큰 예측 (Next Token Prediction)
LLM의 핵심 메커니즘은 단순하다. 지금까지의 텍스트를 보고, 다음에 올 토큰을 예측한다. 이것을 반복한다.
"코드를 생성한다"는 말은 사실 "다음에 올 코드 토큰을 계속 예측한다"는 뜻이다.

기본 메커니즘은 한 토큰씩 전진이지만, 최신 모델은 extended thinking(내부 추론 토큰)을 통해 코드 출력 전에 계획을 세운다. 또한 단일 forward pass에서도 네트워크 내부 representation이 전체 구조 정보를 어느 정도 담고 있다는 연구가 있다. 그럼에도 autoregressive 특성의 한계는 여전히 존재한다.

다음 토큰을 고를 때 "가장 확률 높은 토큰"만 고르는 것은 아니다. 온도(temperature)라는 설정이 선택의 무작위성을 조절한다. 온도가 낮으면 확률 높은 토큰을 거의 그대로 고르고, 높으면 확률이 낮은 토큰도 선택될 수 있다. 같은 프롬프트에 같은 질문을 해도 결과가 매번 다른 이유다. 에이전틱 코딩 도구에서 온도는 사용자가 조절하지 않지만, 이 특성을 알면 "아까는 됐는데 지금은 안 된다"는 상황이 납득된다.

### 어텐션 (Attention)
"이 토큰은 앞의 어떤 토큰들과 관련이 있는가"를 계산하는 메커니즘이다.
함수 호출을 생성할 때, 앞에서 정의한 함수 시그니처에 어텐션이 걸린다.
이 메커니즘 덕분에 LLM은 멀리 떨어진 맥락을 참조할 수 있다.

하지만 어텐션에도 한계가 있다. 모든 토큰에 균일하게 주의를 기울이지 않는다. 이것이 아래에서 다룰 편향의 원인 중 하나다. (최근 편향, 중간 손실 등은 어텐션뿐 아니라 positional encoding, 학습 데이터 분포, RLHF 등 여러 요인이 복합적으로 작용한다.)

### 컨텍스트 윈도우 (Context Window)
LLM이 한 번에 볼 수 있는 토큰의 양에는 한계가 있다. 이것이 컨텍스트 윈도우다.
대화가 길어져서 컨텍스트 윈도우를 초과하면, 구현에 따라 오래된 내용이 잘리거나 에러가 발생한다.
코드베이스 전체를 한 번에 이해하는 것이 아니라, 창문을 통해 일부를 보는 것에 가깝다.

### 학습 데이터 (Training Data)
LLM은 공개 웹 텍스트, 제휴 데이터, 사람의 피드백 등으로 학습되었다.
이것이 의미하는 것: 학습 데이터에 많이 등장한 언어, 프레임워크, 패턴에서 대체로 더 강하다.
Python, Java, JavaScript 같은 메이저 언어에서 일반적으로 잘하는 경향이 있지만, 모델과 태스크에 따라 일부 언어가 Python과 비슷하거나 상회하는 사례도 보고되어 있어 일률적이지는 않다.

## LLM의 특성과 실전 대응

### 1. 최근 편향 (Recency Bias)
**특성**: 긴 대화에서 마지막에 가까운 내용에 더 강하게 영향 받는다.

**대응**:
- 중요한 지시는 대화 끝에 다시 한번 언급한다
- 새 대화를 시작하는 것을 두려워하지 않는다. 맥락이 흐려졌다면 새 대화가 더 낫다

### 2. 중간 손실 (Lost in the Middle)
**특성**: 긴 입력에서 처음과 끝에 비해 가운데 내용에 대한 주의가 떨어지는 경향이 있다. 최신 모델에서는 이 현상이 상당히 완화되었지만, 완전히 사라진 것은 아니다.

**대응**:
- 긴 요구사항을 줄 때, 가장 중요한 것을 처음이나 끝에 배치한다
- 한 번에 많은 요구사항을 전달하기보다, 단계별로 나눈다
- 파일을 읽힐 때도 전체보다는 관련 부분만 보여주는 것이 효과적이다

### 3. 동의 편향 (Sycophancy)
**특성**: 사용자의 말에 동의하려는 경향이 있다. "이 코드 괜찮지?" 하면 "네, 좋습니다" 하기 쉽다.

**대응**:
- "이 코드에 문제가 있나?" 대신 "이 코드의 버그를 찾아줘"처럼 구체적으로 요청한다
- 에이전트의 판단에 의존하기보다, 테스트로 검증한다. 1탄의 핵심: 루프를 닫아야 한다
- "맞아?"라고 물으면 "맞다"고 답할 가능성이 높다. 열린 질문을 한다

### 4. 흔한 답으로 수렴 (Common Pattern Bias)
**특성**: 학습 데이터에서 자주 본 패턴으로 끌려간다. 여기에 정렬(RLHF) 과정, 디코딩 전략, 안전 정책 등도 다양성을 줄이는 방향으로 작용해, "정석적인" 답을 내놓으려 한다.

**대응**:
- 특정한 제약조건이나 스타일이 있다면 명시적으로 말한다
- 프로젝트의 기존 코드를 참조하게 한다. "이 파일의 스타일을 따라줘"
- CLAUDE.md에 프로젝트 컨벤션을 적어두면, 매번 말하지 않아도 된다. 이때 강한 어조로 써야 잘 지켜진다. "WebFetch 실패 시 → Read 도구로 fallback.md를 읽고 그 방법을 따를 것"이라고 썼더니 무시했지만, "반드시 읽고 그 방법을 따를 것. 자체 판단으로 다른 방법을 먼저 시도하지 말 것"으로 바꾸니 지켜졌다

### 5. 상태 추적 부재 (No State Tracking)
**특성**: LLM은 정확한 카운팅이나 상태 추적에 자주 실패한다. 괄호 개수, 들여쓰기 깊이를 실수하기 쉽다.

**대응**:
- 복잡한 중첩 구조보다 평탄한(flat) 코드 구조가 LLM에게 유리하다
- 이것은 사람에게도 좋은 코드다. Early return, 작은 함수
- 에이전트가 생성한 코드의 구문 오류는 린터/포맷터로 자동 검증한다

### 6. 한 토큰씩 전진 (Autoregressive)
**특성**: 단일 생성 과정에서 한번 출력한 토큰은 되돌릴 수 없다. 코드 앞부분을 쓰면서 뒷부분의 구조를 바꿀 수 없다. (에이전트 워크플로에서는 재생성·수정이 가능하지만, 한 번의 생성 안에서는 이 제약이 존재한다.)

**대응**:
- 큰 작업을 작은 단위로 나눈다. 한 번에 1000줄보다 100줄씩 10번이 낫다
- 함수 시그니처(입출력)를 먼저 정의하고, 구현을 요청한다. 앞부분이 확정되어야 뒷부분이 정확해진다
- 1탄에서 말한 "검증 가능한 단위"가 여기서도 통한다

## 정리
LLM의 특성을 알고 나면, 대응법을 정리할 수 있다.
- 작은 단위로 작업하라 → 컨텍스트 윈도우, 중간 손실, 자기회귀 특성 모두에 대한 대응
- 명확하게 말하라 → 동의 편향, 흔한 답 수렴에 대한 대응
- 테스트로 검증하라 → 모든 특성의 한계에 대한 최종 안전망

LLM의 작동원리를 이해하면, 이 조언들이 왜 맞는지 더 깊이 납득할 수 있다.
